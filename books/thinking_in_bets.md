# Thinking in Bets
Author: Annie Duke  
[Amazon](https://amzn.to/3r4AxaO)  
[Goodreads](https://www.goodreads.com/book/show/35957157-thinking-in-bets)  

>The hazards of resulting Take a moment to imagine your best decision in the last year. Now take a moment to imagine your worst decision. I’m willing to bet that your best decision preceded a good result and the worst decision preceded a bad result. That is a safe bet for me because resulting isn’t just something we do from afar. Monday Morning Quarterbacks are an easy target, as are writers and bloggers providing instant analysis to a mass audience. But, as I found out from my own experiences in poker, resulting is a routine thinking pattern that bedevils all of us. Drawing an overly tight relationship between results and decision quality affects our decisions every day, potentially with far-reaching, catastrophic consequences.

>Poker vs. chess In The Ascent of Man, scientist Jacob Bronowski recounted how von Neumann described game theory during a London taxi ride. Bronowski was a chess enthusiast and asked him to clarify. “You mean, the theory of games like chess?” Bronowski quoted von Neumann’s response: “‘No, no,’ he said. ‘Chess is not a game. Chess is a well-defined form of computation. You may not be able to work out the answers, but in theory there must be a solution, a right procedure in any position. Now, real games,’ he said, ‘are not like that at all. Real life is not like that. Real life consists of bluffing, of little tactics of deception, of asking yourself what is the other man going to think I mean to do. And that is what games are about in my theory.’” The decisions we make in our lives—in business, saving and spending, health and lifestyle choices, raising our children, and relationships—easily fit von Neumann’s definition of “real games.” They involve uncertainty, risk, and occasional deception, prominent elements in poker. Trouble follows when we treat life decisions as if they were chess decisions. Chess contains no hidden information and very little luck. The pieces are all there for both players to see. Pieces can’t randomly appear or disappear from the board or get moved from one position to another by chance. No one rolls dice after which, if the roll goes against you, your bishop is taken off the board. If you lose at a game of chess, it must be because there were better moves that you didn’t make or didn’t see. You can theoretically go back and figure out exactly where you made mistakes. If one chess player is more than just a bit better than another, it is nearly inevitable the better player will win (if they are white) or, at least, draw (if they are black). On the rare occasions when a lower-ranked grand master beats a Garry Kasparov, Bobby Fischer, or Magnus Carlsen, it is because the higher-ranked player made identifiable, objective mistakes, allowing the other player to capitalize.

>Poker, in contrast, is a game of incomplete information. It is a game of decision-making under conditions of uncertainty over time. (Not coincidentally, that is close to the definition of game theory.) Valuable information remains hidden. There is also an element of luck in any outcome. You could make the best possible decision at every point and still lose the hand, because you don’t know what new cards will be dealt and revealed. Once the game is finished and you try to learn from the results, separating the quality of your decisions from the influence of luck is difficult. In chess, outcomes correlate more tightly with decision quality. In poker, it is much easier to get lucky and win, or get unlucky and lose. If life were like chess, nearly every time you ran a red light you would get in an accident (or at least receive a ticket). If life were like chess, the Seahawks would win the Super Bowl every time Pete Carroll called that pass play. But life is more like poker. You could make the smartest, most careful decision in firing a company president and still have it blow up in your face. You could run a red light and get through the intersection safely—or follow all the traffic rules and signals and end up in an accident. You could teach someone the rules of poker in five minutes, put them at a table with a world champion player, deal a hand (or several), and the novice could beat the champion. That could never happen in chess.

>If we want to improve in any game—as well as in any aspect of our lives—we have to learn from the results of our decisions. The quality of our lives is the sum of decision quality plus luck. In chess, luck is limited in its influence, so it’s easier to read the results as a signal of decision quality. That more tightly tethers chess players to rationality. Make a mistake and your opponent’s play points it out, or it is capable of analysis afterward. There is always a theoretically right answer out there. If you lose, there is little room to off-load losing to any other explanation than your inferior decision-making. You’ll almost never hear a chess player say, “I was robbed in that game!” or, “I played perfectly and caught some terrible breaks.” (Walk the hallways during a break in a poker tournament and you’ll hear a lot of that.) That’s chess, but life doesn’t look like that. It looks more like poker, where all that uncertainty gives us the room to deceive ourselves and misinterpret the data. Poker gives us the leeway to make mistakes that we never spot because we win the hand anyway and so don’t go looking for them, or the leeway to do everything right, still lose, and treat the losing result as proof that we made a mistake. Resulting, assuming that our decision-making is good or bad based on a small set of outcomes, is a pretty reasonable strategy for learning in chess. But not in poker—or life. Von Neumann and Morgenstern understood that the world doesn’t easily reveal the objective truth. That’s why they based game theory on poker. Making better decisions starts with understanding this: uncertainty can work a lot of mischief. A lethal battle of wits In one of the more famous scenes in The Princess Bride, the Dread Pirate Roberts (the love-besotted Westley) catches up to Vizzini, the mastermind who kidnapped Princess Buttercup. Having vanquished Fezzik the Giant in a battle of strength and having outdueled swordsman Inigo Montoya, the Dread Pirate Roberts proposes he and Vizzini compete in a lethal battle of wits, which provides a great demonstration of the peril of making decisions with incomplete information. The pirate produces a packet of deadly iocane powder and, hiding two goblets of wine from view, he empties the packet, and puts one goblet in front of himself and the other in front of Vizzini. Once Vizzini chooses a goblet, they will both drink “and find out who is right and who is dead.” “It’s all so simple,” Vizzini scoffs. “All I have to do is deduce, from what I know of you, the way your mind works. Are you the kind of man who would put the poison into his own glass, or into the glass of his enemy?” He provides a dizzying series of reasons why the poison can’t (or must) be in one cup, and then in the other. His rant accounts for cleverness, anticipating cleverness, iocane’s origin (the criminal land of Australia), untrustworthiness, anticipating untrustworthiness, and dueling presumptions related to Westley defeating the giant and the swordsman. While explaining all this, Vizzini diverts Westley’s attention, switches the goblets, and declares that they should drink from the goblets in front of them. Vizzini pauses for a moment and, when he sees Westley drink from his own goblet, confidently drinks from the other. Vizzini roars with laughter. “You fell victim to one of the classic blunders. The most famous is ‘Never get involved in a land war in Asia,’ but only slightly less well known is this: ‘Never go in against a Sicilian when death is on the line.’” In the midst of laughing, Vizzini falls over, dead. Buttercup says, “To think, all that time it was your cup that was poisoned.” Westley tells her, “They were both poisoned. I’ve spent the last two years building up immunity to iocane powder.” Like all of us, Vizzini didn’t have all the facts. He considered himself a genius without equal: “Let me put it this way. Have you ever heard of Plato, Aristotle, Socrates? Morons.” But, also like all of us, he underestimated the amount and effect of what he didn’t know. Suppose someone says, “I flipped a coin and it landed heads four times in a row. How likely is that to occur?” It feels like that should be a pretty easy question to answer. Once we do the math on the probability of heads on four consecutive 50-50 flips, we can determine that would happen 6.25% of the time (.50 × .50 × .50 × .50). That’s making the same mistake as Vizzini. The problem is that we came to this answer without knowing anything about the coin or the person flipping it. Is it a two-sided coin or three-sided or four? If it is two-sided, is it a two-headed coin? Even if the coin is two-sided (heads and tails), is the coin weighted to land on heads more often than tails (but maybe not always)? Is the flipper a magician who is capable of influencing how the coin lands? This information is all incomplete, yet we answered the question as if we had examined the coin and knew everything about it. We never considered that both goblets might be poisoned. (“Inconceivable” would have been Vizzini’s term, had he been able to comment on his own death.) Now if that person flipped the coin 10,000 times, giving us a sufficiently large sample size, we could figure out, with some certainty, whether the coin is fair. Four flips simply isn’t enough to determine much about the coin. We make this same mistake when we look for lessons in life’s results. Our lives are too short to collect enough data from our own experience to make it easy to dig down into decision quality from the small set of results we experience. If we buy a house, fix it up a little, and sell it three years later for 50% more than we paid, does that mean we are smart at buying and selling property, or at fixing up houses? It could, but it could also mean there was a big upward trend in the market and buying almost any piece of property would have made just as much money. Or maybe buying that same house and not fixing it up at all might have resulted in the same (or even better) profit. A lot of previously successful house flippers had to face that real possibility between 2007 and 2009. When someone asks you about a coin they flipped four times, there is a correct answer: “I’m not sure.”

>What if we shifted our definition of “I don’t know” from the negative frame (“I have no idea” or “I know nothing about that,” which feels like we lack competence or confidence) to a more neutral frame? What if we thought about it as recognizing that, although we might know something about the chances of some event occurring, we are still not sure how things will turn out in any given instance? That is just the truth. If we accept that, “I’m not sure” might not feel so bad. What good poker players and good decision-makers have in common is their comfort with the world being an uncertain and unpredictable place. They understand that they can almost never know exactly how something will turn out. They embrace that uncertainty and, instead of focusing on being sure, they try to figure out how unsure they are, making their best guess at the chances that different outcomes will occur. The accuracy of those guesses will depend on how much information they have and how experienced they are at making such guesses. This is part of the basis of all bets.

>The secret is to make peace with walking around in a world where we recognize that we are not sure and that’s okay. As we learn more about how our brains operate, we recognize that we don’t perceive the world objectively. But our goal should be to try.

>At one such tournament, I told the audience that one player would win 76% of the time and the other would win 24% of the time. I dealt the remaining cards, the last of which turned the 24% hand into the winner. Amid the cheers and groans, someone in the audience called out, “Annie, you were wrong!” In the same spirit that he said it, I explained that I wasn’t. “I said that would happen 24% of the time. That’s not zero. You got to see part of the 24%!” A few hands later, almost the same thing happened. Two players put all of their chips in the pot and they turned their cards faceup. One player was 18% to win and the other 82% to win the hand. Again, the player with the worse hand when they put in their chips hit a subsequent lucky card to win the pot. This time that same guy in the crowd called out, “Look, it was the 18%!” In that aha moment, he changed his definition of what it meant to be wrong. When we think in advance about the chances of alternative outcomes and make a decision based on those chances, it doesn’t automatically make us wrong when things don’t work out. It just means that one event in a set of possible futures occurred. Look how quickly you can begin to redefine what it means to be wrong. Once we start thinking like this, it becomes easier to resist the temptation to make snap judgments after results or say things like “I knew it” or “I should have known.” Better decision-making and more self-compassion follow. The public-at-large is often guilty of making black-and-white judgments about the “success” or “failure” of probabilistic thinking. When the UK voted to leave the European Union (“Brexit”) in July 2016, it was an unlikely result. Betting shops had set odds heavily favoring a vote for Remain. That does not mean the betting shops had an opinion that Remain would win the day. The goal of the bookmaker is to make sure the amount of money bet on either side is equal, so that the losers essentially pay the winners while the bookmaker just takes their fee. They aim to have no stake in the outcome and adjust the odds accordingly. The bookmaker’s odds reflect the market’s view, essentially our collective best guess of what is fair.

>When we think probabilistically, we are less likely to use adverse results alone as proof that we made a decision error, because we recognize the possibility that the decision might have been good but luck and/or incomplete information (and a sample size of one) intervened. Maybe we made the best decision from a set of unappealing choices, none of which were likely to turn out well. Maybe we committed our resources on a long shot because the payout more than compensated for the risk, but the long shot didn’t come in this time. Maybe we made the best choice based on the available information, but decisive information was hidden and we could not have known about it. Maybe we chose a path with a very high likelihood of success and got unlucky. Maybe there were other choices that might have been better and the one we made wasn’t wrong or right but somewhere in between. The second-best choice isn’t wrong. By definition, it is more right (or less wrong) than the third-best or fourth-best choice. It is like the scale at the doctor’s office: there are a lot more choices other than the extremes of obesity or anorexia. For most of our decisions, there will be a lot of space between unequivocal “right” and “wrong.” When we move away from a world where there are only two opposing and discrete boxes that decisions can be put in—right or wrong—we start living in the continuum between the extremes. Making better decisions stops being about wrong or right but about calibrating among all the shades of grey.

>By treating decisions as bets, poker players explicitly recognize that they are deciding on alternative futures, each with benefits and risks. They also recognize there are no simple answers. Some things are unknown or unknowable. The promise of this book is that if we follow the example of poker players by making explicit that our decisions are bets, we can make better decisions and anticipate (and take protective measures) when irrationality is likely to keep us from acting in our best interest.

>We don’t think of our parenting choices as bets but they are. We want our children to be happy, productive adults when we send them out into the world. Whenever we make a parenting choice (about discipline, nutrition, school, parenting philosophy, where to live, etc.), we are betting that our choice will achieve the future we want for our children more than any other choice we might make given the constraints of the limited resources we have to allocate—our time, our money, our attention. Job and relocation decisions are bets. Sales negotiations and contracts are bets. Buying a house is a bet. Ordering the chicken instead of the steak is a bet. Everything is a bet.

>How can we be sure that we are choosing the alternative that is best for us? What if another alternative would bring us more happiness, satisfaction, or money? The answer, of course, is we can’t be sure. Things outside our control (luck) can influence the result. The futures we imagine are merely possible. They haven’t happened yet. We can only make our best guess, given what we know and don’t know, at what the future will look like. If we’ve never lived in Des Moines, how can we possibly be sure how we will like it? When we decide, we are betting whatever we value (happiness, success, satisfaction, money, time, reputation, etc.) on one of a set of possible and uncertain futures. That is where the risk is. Poker players live in a world where that risk is made explicit. They can get comfortable with uncertainty because they put it up front in their decisions. Ignoring the risk and uncertainty in every decision might make us feel better in the short run, but the cost to the quality of our decision-making can be immense. If we can find ways to become more comfortable with uncertainty, we can see the world more accurately and be better for it.

>Wanna bet? Imagine taking part in a conversation with a friend about the movie Citizen Kane. Best film of all time, introduced a bunch of new techniques by which directors could contribute to storytelling. “Obviously, it won the best-picture Oscar,” you gush, as part of a list of superlatives the film unquestionably deserves. Then your friend says, “Wanna bet?” Suddenly, you’re not so sure. That challenge puts you on your heels, causing you to back off your declaration and question the belief that you just declared with such assurance. When someone challenges us to bet on a belief, signaling their confidence that our belief is inaccurate in some way, ideally it triggers us to vet the belief, taking an inventory of the evidence that informed us. How do I know this? Where did I get this information? Who did I get it from? What is the quality of my sources? How much do I trust them? How up to date is my information? How much information do I have that is relevant to the belief? What other things like this have I been confident about that turned out not to be true? What are the other plausible alternatives? What do I know about the person challenging my belief? What is their view of how credible my opinion is? What do they know that I don’t know? What is their level of expertise? What am I missing?
Redefining confidence

>Location 931
We would be better served as communicators and decision-makers if we thought less about whether we are confident in our beliefs and more about how confident we are. Instead of thinking of confidence as all-or-nothing (“I’m confident” or “I’m not confident”), our expression of our confidence would then capture all the shades of grey in between. When we express our beliefs (to others or just to ourselves as part of our internal decision-making dialogue), they don’t generally come with qualifications. What if, in addition to expressing what we believe, we also rated our level of confidence about the accuracy of our belief on a scale of zero to ten? Zero would mean we are certain a belief is not true. Ten would mean we are certain that our belief is true. A zero-to-ten scale translates directly to percentages. If you think the belief rates a three, that means you are 30% sure the belief is accurate. A nine means you are 90% sure. So instead of saying to ourselves, “Citizen Kane won the Oscar for best picture,” we would say, “I think Citizen Kane won the Oscar for best picture but I’m only a six on that.” Or “I’m 60% that Citizen Kane won the Oscar for best picture.” That means your level of certainty is such that 40% of the time it will turn out that Citizen Kane did not win the best-picture Oscar. Forcing ourselves to express how sure we are of our beliefs brings to plain sight the probabilistic nature of those beliefs, that what we believe is almost never 100% or 0% accurate but, rather, somewhere in between. In a similar vein, the number can reflect several different kinds of uncertainty. “I’m 60% confident that Citizen Kane won best picture” reflects that our knowledge of this past event is incomplete. “I’m 60% confident the flight from Chicago will be late” incorporates a mix of our incomplete knowledge and the inherent uncertainty in predicting the future (e.g., the weather might intervene or there might be an unforeseen mechanical issue). We can also express how confident we are by thinking about the number of plausible alternatives and declaring that range. For example, if I am stating my belief about what age Elvis died, I might say, “Somewhere between age forty and forty-seven.” I know he died in his forties and I remember that it was his earlier forties, so for me this is the range of plausible alternatives. The more we know about a topic, the better the quality of information we have, the tighter the range of plausible alternatives. (When it comes to predictions, the plausible range of outcomes would also be tighter when there is less luck involved.) The less we know about a topic or the more luck involved, the wider our range.

>When scientists publish results of experiments, they share with the rest of their community their methods of gathering and analyzing the data, the data itself, and their confidence in that data. That makes it possible for others to assess the quality of the information being presented, systematized through peer review before publication. Confidence in the results is expressed through both p-values, the probability one would expect to get the result that was actually observed (akin to declaring your confidence on a scale of zero to ten), and confidence intervals (akin to declaring ranges of plausible alternatives). Scientists, by institutionalizing the expression of uncertainty, invite their community to share relevant information and to test and challenge the results and explanations. The information that gets shared back might confirm, disconfirm, or refine published hypotheses. The goal is to advance knowledge rather than affirm what we already believe. This is why science advances at a fast clip.* By communicating our own uncertainty when sharing beliefs with others, we are inviting the people in our lives to act like scientists with us. This advances our beliefs at a faster clip because we miss out on fewer opportunities to get new information, information that would help us to calibrate the beliefs we have.

>This problem is top of mind for poker players. Most poker hands end in a cloud of incomplete information: one player bets, no one calls the bet, the bettor is awarded the pot, and no one is required to reveal their hidden cards. After those hands, the players are left guessing why they won or lost the hand. Did the winner have a superior hand? Did the loser fold the best hand? Could the player who won the hand have made more money if they chose a different line of play? Could the player who lost have made the winner forfeit if they chose to play the hand differently? In answering these questions, none of the players knows what cards their opponents actually held, or how the players would have reacted to a different sequence of betting decisions. How poker players adjust their play from experience determines their future results. How they fill in all those blanks is a vitally important bet on whether they get better at the game.

>And the first step to doing this well is in recognizing that things sometimes happen because of the other form of uncertainty: luck. Luck vs. skill: fielding outcomes The way our lives turn out is the result of two things: the influence of skill and the influence of luck. For the purposes of this discussion, any outcome that is the result of our decision-making is in the skill category. If making the same decision again would predictably result in the same outcome, or if changing the decision would predictably result in a different outcome, then the outcome following that decision was due to skill. The quality of our decision-making was the main influence over how things turned out. If, however, an outcome occurs because of things that we can’t control (like the actions of others, the weather, or our genes), the result would be due to luck. If our decisions didn’t have much impact on the way things turned out, then luck would be the main influence.*

>Chalk up an outcome to skill, and we take credit for the result. Chalk up an outcome to luck, and it wasn’t in our control. For any outcome, we are faced with this initial sorting decision. That decision is a bet on whether the outcome belongs in the “luck” bucket or the “skill” bucket. This is where Nick the Greek went wrong. We can update the learning loop to represent this like so:

>Rats get tripped up by uncertainty in a way that should appear very familiar to us. Classical stimulus-response experiments have shown that the introduction of uncertainty drastically slows learning. When rats are trained on a fixed reward schedule (for example, a pellet for every tenth press of a lever), they learn pretty fast to press that lever for food. If you withdraw the reward, the lever-pressing behavior is quickly extinguished. The rats figure out that no more food is on its way. But when you reward the rats on a variable or intermittent reinforcement schedule (a pellet that comes on average every tenth lever press), that introduces uncertainty. The average number of lever presses for the reward is the same, but the rat could get a reward on the next press or not for thirty presses. In other words, the rats are rewarded the way humans usually are: having no way to know with certainty what will happen on the next try. When you withdraw the reward from those rats, the lever-pressing behavior extinguishes only after a very long time of fruitless lever pushing, sometimes thousands of tries. We might imagine the rats thinking, “I bet the next lever press will get me a pellet. . . . I’ve just been getting unlucky . . . I’m due.” Actually, we don’t even have to imagine this. We can hear it if we listen to what people say while they play slot machines. Slot machines operate on a variable-payoff system. It’s no wonder that, despite those machines being among the worst bets in the casino, the banks of slots in a casino are packed. In the end, our rat brains dominate. If this all doesn’t seem difficult enough, outcomes are rarely all skill or all luck. Even when we make the most egregious mistakes and get appropriately negative outcomes, luck plays a role. For every drunk driver who swerves into a ditch and flips his car, there are several who swerve harmlessly across multilane highways. It might feel like the drunk driver in the ditch deserved that outcome, but the luck of the road conditions and presence or absence of other drivers also played a role. When we do everything right, like drive through a green light perfectly sober and live to tell the tale, there is also an element of luck. No one else simultaneously ran a red light and hit us. There wasn’t a patch of ice on the road to make us lose control of our vehicle. We didn’t run over a piece of debris and blow a tire. When we field our outcomes as the future unfolds, we always run into this problem: the way things turn out could be the result of our decisions, luck, or some combination of the two. Just as we are almost never 100% wrong or right, outcomes are almost never 100% due to luck or skill.

>I described this pattern during an address at a meeting of the International Academy of Trial Lawyers (IATL). One lawyer in the audience rushed to tell me after the speech about a senior partner he trained under when he was first out of law school. “You won’t believe how on-point this is, Annie. I assisted this partner at several trials and at the end of each day, he would analyze the witness testimony the same way. If the witness helped our case, he would say, ‘You see how well I prepared that witness? When you know how to prepare a witness, you get the results you want.’ If the witness hurt our case, he would tell me, ‘That guy refused to listen to me.’ It never varied.” I’m betting any parent of a school-aged child knows this. On occasions when my kids have done poorly on a test, it seems to have never been because they didn’t study. “The teacher doesn’t like me. Everybody did poorly. The teacher put material on the test we didn’t cover in class. You can ask anyone!” Self-serving bias is a deeply embedded and robust thinking pattern. Understanding why this pattern emerges is the first step to developing practical strategies to improve our ability to learn from experience. These strategies encourage us to be more rational in the way we field outcomes, fostering open-mindedness in considering all the possible causes of an outcome, not just the ones that flatter us.

>Fielding outcomes with the goal of promoting our self-narrative and doing it in an all-or-nothing fashion alters our ability to make smart bets about why the future unfolded in a particular way. Learning from experience is difficult—and sometimes impossible—with this kind of biased, broad-brush thinking. Outcomes are rarely the result of our decision quality alone or chance alone, and outcome quality is not a perfect indicator of the influence of luck or skill. When it comes to self-serving bias, we act as if our good outcomes are perfectly correlated to good skill and our bad outcomes are perfectly correlated to bad luck.* Whether it is a poker hand, an auto accident, a football call, a trial outcome, or a business success, there are elements of luck and skill in virtually any outcome. That the motivation to update our self-image in a positive way underlies self-serving bias gives us an idea of where we might look for solutions to overcome the bias. Maybe we could stop clinging to ego, giving up on that need to have a positive narrative of our lives. Maybe we could still drive a positive narrative but, instead of updating through credit and blame, we could get off on striving to be more objective and open-minded in assessing the influence of luck and skill on our outcomes. Maybe we could put in the time and hard work to retrain the way we process results, moving toward getting our positive self-image updates from accurate fielding, from truthseeking.

>Not only are all those other people’s outcomes plentiful, they are also free (aside from any ante). When a poker player chooses to play a hand, they are putting their own money at risk. When a poker player is just watching the game, they get to sit back while other people put money at risk. That’s an opportunity to learn at no extra cost. When any of us makes decisions in life away from the poker table, we always have something at risk: money, time, health, happiness, etc. When it’s someone else’s decision, we don’t have to pay to learn. They do. There’s a lot of free information out there. Unfortunately, learning from watching others is just as fraught with bias. Just as there is a pattern in the way we field our own outcomes, we field the outcomes of our peers predictably. We use the same black-and-white thinking as with our own outcomes, but now we flip the script. Where we blame our own bad outcomes on bad luck, when it comes to our peers, bad outcomes are clearly their fault. While our own good outcomes are due to our awesome decision-making, when it comes to other people, good outcomes are because they got lucky. As artist and writer Jean Cocteau said, “We must believe in luck. For how else can we explain the success of those we don’t like?”

>We think we know the ingredients for happiness. Sonja Lyubomirsky, a psychology professor at the University of California, Riverside, and popular author on the subject of happiness, summarized several reviews of the literature on the elements we commonly consider: “a comfortable income, robust health, a supportive marriage, and lack of tragedy or trauma.” Lyubomirsky noted, however, that “the general conclusion from almost a century of research on the determinants of well-being is that objective circumstances, demographic variables, and life events are correlated with happiness less strongly than intuition and everyday experience tell us they ought to be. By several estimates, all of these variables put together account for no more than 8% to 15% of the variance in happiness.” What accounts for most of the variance in happiness is how we’re doing comparatively.

>A lot of the way we feel about ourselves comes from how we think we compare with others. This robust and pervasive habit of mind impedes learning. Luckily, habits can be changed, whether the habit is biting your nails or decrying your terrible luck when you lose. By shifting what it is that makes us feel good about ourselves, we can move toward a more rational fielding of outcomes and a more compassionate view of others. We can learn better and be more open-minded if we work toward a positive narrative driven by engagement in truthseeking and striving toward accuracy and objectivity: giving others credit when it’s due, admitting when our decisions could have been better, and acknowledging that almost nothing is black and white.

>“Wanna bet?” redux Treating outcome fielding as a bet can accomplish the mindset shift necessary to reshape habit. If someone challenged us to a meaningful bet on how we fielded an outcome, we would find ourselves quickly moving beyond self-serving bias. If we wanted to win that bet, we wouldn’t reflexively field bad outcomes as all luck or good ones as all skill. (If you walked into a poker room and threw around words like “always” and “never,” you’d soon find yourself challenged to a bunch of bets. It’s easy to win a bet against someone who takes extreme positions.) Imagine getting into an accident at an intersection after losing control of your car on a patch of ice you couldn’t see. Your first thought would likely be that you got unlucky. But what if you had to bet on that? Depending on the details, there would be a lot of alternatives to just plain bad luck you would now consider. Based on the weather, maybe you could have anticipated some ice on the road. Maybe you were driving too fast for the weather conditions. Once the car started sliding, maybe you could have steered differently or maybe you pumped the brakes when you shouldn’t have. Maybe you could have taken a safer route, choosing a main road that would have been salted. Maybe you should have kept the Mustang in the garage and taken the Suburban. Some of the reasons we come up with may be easy to discount. And some may not. The key is that in explicitly recognizing that the way we field an outcome is a bet, we consider a greater number of alternative causes more seriously than we otherwise would have. That is truthseeking. This is what Phil Ivey does. The prospect of a bet makes us examine and refine our beliefs, in this case the belief about whether luck or skill was the main influence in the way things turned out. Betting on what we believe makes us take a closer look by making explicit what is already implicit: we have a great deal at risk in assessing why anything turned out the way it did. That sure sounds like a bet worth taking seriously. When we treat outcome fielding as a bet, it pushes us to field outcomes more objectively into the appropriate buckets because that is how bets are won. Winning feels good. Winning is a positive update to our personal narrative. Winning is a reward. With enough practice, reinforced by the reward of feeling good about ourselves, thinking of fielding outcomes as bets will become a habit of mind. Thinking in bets triggers a more open-minded exploration of alternative hypotheses, of reasons supporting conclusions opposite to the routine of self-serving bias. We are more likely to explore the opposite side of an argument more often and more seriously—and that will move us closer to the truth of the matter.

>Once we start actively training ourselves in testing alternative hypotheses and perspective taking, it becomes clear that outcomes are rarely 100% luck or 100% skill.